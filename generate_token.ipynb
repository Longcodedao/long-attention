{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ccfb57-032c-4fe9-83e2-6710dca9e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# --- IMPORT YOUR CUSTOM MODEL CLASSES ---\n",
    "# We must import these exactly as you do in your training script\n",
    "from model.configuration_holo import HoloConfig\n",
    "from model.modeling_holo import HoloForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f1344c7-1051-4a32-ad90-6234969c8deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./holo_final_model...\n",
      "Model loaded! Generating text...\n",
      "\n",
      "------------------------------\n",
      "Input: The capital of France is\n",
      "Output: The capital of France is known for its rich history and is believed to be the most famous of the state.\n",
      "According to official records, the first recorded recorded is a large scale in 1612, when the first recorded recorded recorded was recorded. The first recorded recorded recorded was\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "path = \"./holo_final_model\"\n",
    "\n",
    "print(f\"Loading model from {path}...\")\n",
    "\n",
    "# 1. Load the Configuration\n",
    "config = HoloConfig.from_pretrained(path)\n",
    "\n",
    "# 2. Load the Model using YOUR custom class\n",
    "# We map it to CUDA if available for speed\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = HoloForCausalLM.from_pretrained(path, config=config).to(device)\n",
    "\n",
    "# 3. Load the Tokenizer\n",
    "# (AutoTokenizer usually works fine if tokenizer_config.json is saved correctly)\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "\n",
    "# Ensure the tokenizer has a pad token (often missing in Llama/Mistral bases)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Model loaded! Generating text...\\n\")\n",
    "\n",
    "# --- GENERATION TEST ---\n",
    "input_text = \"The capital of France is\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=50, \n",
    "        do_sample=True,   # Add sampling to see if it varies\n",
    "        temperature=0.7, \n",
    "        top_k=50,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "# Decode and Print\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"-\" * 30)\n",
    "print(f\"Input: {input_text}\")\n",
    "print(f\"Output: {generated_text}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b7a47dd-9bd6-46be-abd5-1f325fbb69d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Try generation\n",
      "Input: The capital of France is\n",
      "Output: The capital of France is located in France, and it is not known for its great location. It is the easiest way to visit the town of Paris, which is located in the middle of France. It is a perfect place to walk through the natural beauty of the city.\n",
      "------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------\n",
      "Try generation\n",
      "Input: The capital of France is\n",
      "Output: The capital of France is one of the most valuable and most influential people in France.\n",
      "Today we are celebrating the first year of the Spanish-speaking region of France. Here we take a look at the history of the Spanish-speaking population and why Spain is the most popular\n",
      "------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------\n",
      "Try generation\n",
      "Input: The capital of France is\n",
      "Output: The capital of France is the biggest city in the world – and it's one of the most popular cities in the world.\n",
      "The city is also the largest city in the world – and it's one of the most diverse cities in the world.\n",
      "The city is also\n",
      "------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------\n",
      "Try generation\n",
      "Input: The capital of France is\n",
      "Output: The capital of France is expected to be a massive success for France. This is the only reason that France is known for its enormous cultural heritage. This is because it has a fascinating history of many historical and historical subjects. It is interesting to see how many people can participate in\n",
      "------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------\n",
      "Try generation\n",
      "Input: The capital of France is\n",
      "Output: The capital of France is the most populous city in France with a population of 2.6 million inhabitants and is expected to reach an average of 6.6 million inhabitants. The population of France is estimated to be around 2.7 million. The population of France is expected to\n",
      "------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=50, \n",
    "            do_sample=True,   # Add sampling to see if it varies\n",
    "            temperature=0.7, \n",
    "            top_k=50,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode and Print\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Try generation\")\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"Output: {generated_text}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeba697-e1c0-4a95-8e5e-97d15639f998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MyProject)",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
