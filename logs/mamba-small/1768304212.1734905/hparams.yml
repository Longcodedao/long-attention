batch_size: 32
checkpoint_dir: ./checkpoints/mamba-small
dataset: slimpajama_6b
eval_steps: 2000
grad_accum_steps: 4
gradient_checkpointing: false
log_dir: ./logs/mamba-small
lr: 0.0007
max_steps: 46000
model_size: small
model_type: mamba
output_dir: ./output/mamba-small
resume_from_checkpoint: null
save_steps: 5000
seq_len: 512
val_dataset: slimpajama_6b
warmup_steps: 2000
