batch_size: 32
checkpoint_dir: ./checkpoints/gpt2-small
dataset: slimpajama_6b
eval_steps: 5000
grad_accum_steps: 4
gradient_checkpointing: false
log_dir: ./logs/gpt2-small
lr: 0.0003
max_steps: 46000
model_size: small
model_type: gpt2
output_dir: ./output/gpt2-small
resume_from_checkpoint: null
save_steps: 5000
seq_len: 512
val_dataset: slimpajama_6b
warmup_steps: 2000
