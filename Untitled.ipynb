{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ce19ee-5fd4-4cfb-902f-99a350cdc072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b21701c2f92427fa64f26e3f219dd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9033f226bd10497e98201b2e5b71d677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78dc334ca55948c9a6375d17ffc3995f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0eaf3e773a472d99347f0ac4d94ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5ff347094546b29daf642cf2263be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model Loader] Identified Vocab Size: 50257\n",
      "[Model Loader] Initializing Long LLM (small)...\n",
      "LongForCausalLM(\n",
      "  (long_model): LongModel(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (layers): ModuleList(\n",
      "      (0-17): 18 x LongBlock(\n",
      "        (attn): LongAttention(\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          (conv): Conv1d(768, 768, kernel_size=(4,), stride=(1,), padding=(3,), groups=768)\n",
      "          (input_gate_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (output_gate_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (gamma_proj): Linear(in_features=768, out_features=12, bias=True)\n",
      "          (o_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (grp_norm): GroupNorm(12, 768, eps=1e-05, affine=True)\n",
      "          (mem_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (mlp): LongMLP(\n",
      "          (w_gate): Linear(in_features=768, out_features=2048, bias=False)\n",
      "          (w_val): Linear(in_features=768, out_features=2048, bias=False)\n",
      "          (w_out): Linear(in_features=2048, out_features=768, bias=False)\n",
      "        )\n",
      "        (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import argparse\n",
    "import datasets\n",
    "import datetime\n",
    "import transformers\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "from torchmetrics import MeanMetric\n",
    "from rich.live import Live\n",
    "from rich.panel import Panel\n",
    "from rich.console import Group\n",
    "from rich.table import Table\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# --- LOCAL IMPORTS ---\n",
    "from model import model_loader\n",
    "from dataset import data_loader\n",
    "import utils\n",
    "import torch.distributed as dist\n",
    "# Disable standard progress bars to let Rich handle the UI\n",
    "datasets.disable_progress_bar()\n",
    "datasets.utils.logging.set_verbosity_error()\n",
    "transformers.utils.logging.set_verbosity_error()\n",
    "warnings.filterwarnings(\"ignore\", message=\".*barrier().*\")\n",
    "\n",
    "model, tokenizer = model_loader.get_model_and_tokenizer(\n",
    "    model_type= \"long\",\n",
    "    model_size= \"small\",\n",
    "    seq_len= 1024,\n",
    ")\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215bc800-271a-4859-a536-ab0ac10919b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MyProject)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
